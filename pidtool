#!/usr/bin/env python

from __future__ import print_function
import argparse
import numpy as np
from numpy.random import choice
import logging


logging.basicConfig(level=logging.INFO)

class Resampler:

    def __init__(self, *args):
        self.edges = args

        # Choose histogram size according to bin edges
        self.histogram = np.zeros(map(lambda x: len(x) - 1, self.edges))

    def learn(self, features, weights=None):
        assert(len(features) == len(self.edges))

        h , _ = np.histogramdd(features.T, bins=self.edges, weights=weights)
        self.histogram += h

    def sample(self, *args):

        assert(len(args) == len(self.edges) - 1)

        args = np.array(args)

        idx = []
        mask = np.zeros(args.shape[1], dtype=bool)
        # Choose bins of conditional features
        for edges, vals in zip(self.edges, args):
            ix = np.searchsorted(edges, vals)
            # If the result is outside of our range, we can't sample
            mask |= (ix == 0) | (ix == len(edges))
            ix[(ix==0) | ix==len(edges)] = 1
            idx.append(ix - 1)
        # Take everything from target feature
        idx.append(Ellipsis)
    
        tmp = self.histogram[idx]
        tmp[tmp < 0] = 0
        norm = np.sum(tmp, axis=1)
        probs = tmp / norm[:,np.newaxis]

        sampled_bin = []
        for i in range(tmp.shape[0]):
            sampled_bin.append(choice(tmp.shape[1], p=probs[i,:]))
        sampled_bin = np.array(sampled_bin)
        sampled_val = np.random.uniform(self.edges[-1][sampled_bin],
                                        self.edges[-1][sampled_bin + 1],
                                        size=len(sampled_bin))

        # If the histogram is empty, we can't sample
        # print( args[:,norm==0])
        # print (self.edges)
        # print (args[:,mask])
        sampled_val[norm == 0] = np.nan
        sampled_val[mask] = np.nan


        return sampled_val

def rooBinning_to_list(rooBinning):
    return [rooBinning.binLow(i) for i in range(rooBinning.numBins())]+[rooBinning.binHigh(rooBinning.numBins()-1)]

def grab_data(option):
    from root_pandas import read_root
    from pandas import DataFrame
    import json
    import sys
    import ROOT
    from ROOT import TFile
    import subprocess
    import re

    def wrap_iter(it):
        elem = it.Next()
        while elem:
            yield elem
            elem = it.Next()

    logging.info("Saving nTuples to " + options.output)

    with open('config.json') as f:
        locations = json.load(f)

    for sample in locations:
        output = options.output +'/{particle}_Stripping{stripping}_Magnet{magnet}.root'.format(**sample)
        ff = TFile(output, 'recreate')
        ff.Close()
        for input in sample['paths']:
            logging.info('Opening file {}'.format(input))
            f = TFile.Open(input)
            ws = f.Get(f.GetListOfKeys().First().GetName())
            ROOT.SetOwnership(ws, False)
            data = ws.allData().front()
            ROOT.RooAbsData.setDefaultStorageType(ROOT.RooAbsData.Tree)
            ff = TFile(output, 'update')
            dset = ROOT.RooDataSet('tree', 'tree', data.get(), ROOT.RooFit.Import(data))
            logging.info('Saving data to {}'.format(output))
            dset.tree().Write('tree')
            ff.Close()
            try:
                # Sometimes, RooFit will segfault when cleaning up :)
                ws.Delete()
            except:
                from IPython import embed;
                embed()

def create_resamplers(options):
    import sys
    import os.path
    import numpy as np
    import pickle
    import json
    from root_pandas import read_root
    from PIDPerfScripts.Binning import GetBinScheme

    #pid_variables = ['V3ProbNNK', 'V3ProbNNpi', 'V3ProbNNmu', 'V3ProbNNp']
    pid_variables = ['CombDLLK','CombDLLmu','CombDLLp','CombDLLe']
    kin_variables = ['{}_P', '{}_Eta','nTracks']

    binning_ProbNN = np.linspace(0, 1, 100)
    binning_DLL = np.append([-1001],np.linspace(-150,150,300))

    with open('config.json') as f:
        locations = json.load(f)

    for sample in locations:
        binning_P = rooBinning_to_list(GetBinScheme(sample['branch_particle'],"P",None)) #last argument takes name of user-defined binning
        binning_ETA = rooBinning_to_list(GetBinScheme(sample['branch_particle'],"ETA",None)) #last argument takes name of user-defined binning TODO: let user pass this argument 
        binning_nTracks = rooBinning_to_list(GetBinScheme(sample['branch_particle'],"nTracks",None)) #last argument takes name of user-defined binning TODO: let user pass this argument
    	
        data = options.location + '/{particle}_Stripping{stripping}_Magnet{magnet}.root'.format(**sample)
        resampler_location = '{particle}_Stripping{stripping}_Magnet{magnet}.pkl'.format(**sample)
        resamplers = dict()
        deps = map(lambda x: x.format(sample['branch_particle']), kin_variables)
        pids = map(lambda x: sample['branch_particle'] + '_' + x, pid_variables)
        for pid in pids:
            #resamplers[pid] = Resampler(binning_P, binning_ETA, binning_ProbNN)
            resamplers[pid] = Resampler(binning_P, binning_ETA, binning_nTracks, binning_DLL)
        for i, chunk in enumerate(read_root(data, variables=deps + pids + ['nsig_sw'], chunksize=100000)):
            for pid in pids:
                resamplers[pid].learn(chunk[deps + [pid]].values.T, weights=chunk['nsig_sw'])
            logging.info('Finished chunk {}'.format(i))
        with open(resampler_location, 'wb') as f:
            pickle.dump(resamplers, f)


def resample_branch(options):

    import pickle
    from root_pandas import read_root

    with open(options.resamplers, 'rb') as f:
        resamplers = pickle.load(f)
    try:
        resamp = resamplers[options.pid_to_sample]
    except KeyError as e:
        raise KeyError("There is no resampler for"+options.pid_to_sample+". The available resamplers are: "+str(resamplers.keys()))

    chunksize=100000

    for i, chunk in enumerate(read_root(options.location, ignore=["*_COV_"], chunksize=chunksize)):
        deps = chunk[options.dependents]
        chunk[options.target] = resamp.sample(*deps.as_matrix().T)
        chunk.to_root('out.root',mode="a")

        logging.info('Processed {} entries'.format((i+1) * chunksize))

parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers()

grab = subparsers.add_parser('grab_data', help='Downloads PID calib data from EOS and saves it as NTuples')
grab.set_defaults(func=grab_data)
grab.add_argument('output')

create = subparsers.add_parser('create_resamplers', help='Generates resampling histograms from NTuples')
create.set_defaults(func=create_resamplers)
create.add_argument("location")

resample = subparsers.add_parser('resample_branch', help='Uses histograms to add resampled PID branches to a dataset')
resample.set_defaults(func=resample_branch)

resample.add_argument("resamplers")
resample.add_argument("pid_to_sample")
resample.add_argument("location")
resample.add_argument("dependents", nargs='+')
resample.add_argument("target")

if __name__ == '__main__':
    options = parser.parse_args()
    options.func(options)
    
